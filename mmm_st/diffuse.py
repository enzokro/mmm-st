# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_diffuse.ipynb.

# %% auto 0
__all__ = ['BaseTransformer', 'ImageTransformer', 'EdgeImageTransformer', 'PoseImageTransformer', 'CombinedImageTransformer',
           'get_transformer']

# %% ../nbs/01_diffuse.ipynb 2
import numpy as np
from PIL import Image
import cv2
from fastcore.basics import store_attr
from diffusers import AutoPipelineForImage2Image
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
import torch
from diffusers.utils import load_image
from controlnet_aux import OpenposeDetector
from .config import Config


# %% ../nbs/01_diffuse.ipynb 3
class BaseTransformer:
    def __init__(
            self,
            model_name=Config.MODEL_NAME,
            device='cuda',
        ):
        store_attr()
        
    def transform_image(self, image, prompt):
        raise NotImplementedError("This method should be overridden by subclasses.")
    
    def __call__(self, *args, **kwargs):
        return self.transform_image(*args, **kwargs)

# %% ../nbs/01_diffuse.ipynb 4
class ImageTransformer(BaseTransformer):
    """
    A class to manage image transformation using the Hugging Face diffusers pipeline.
    """
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.pipeline = self._initialize_pipeline()

    def _initialize_pipeline(self):
        """
        Initializes the img2img pipeline with model settings optimized for performance.
        """
        pipe = AutoPipelineForImage2Image.from_pretrained(
            self.model_name,
            torch_dtype=torch.float16,
            use_safetensors=True,
        ).to(self.device)
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        pipe.enable_model_cpu_offload()
        return pipe

    def transform_image(self, image, prompt):
        """
        Transforms an image based on a given prompt using a pre-trained model.

        Args:
            image: A numpy array of the image to transform.
            prompt (str): The creative prompt to guide the image transformation.

        Returns:
            PIL.Image: The transformed image.
        """
        transformed_image = self.pipeline(prompt, image=image).images[0]
        return transformed_image

# %% ../nbs/01_diffuse.ipynb 5
class EdgeImageTransformer(BaseTransformer):
    def __init__(
            self,
            *args, 
            canny_control_model=Config.CONTROL_NET_CANNY_MODEL,
            **kwargs,
        ):
        super().__init__(*args, **kwargs)
        self.canny_control_model = canny_control_model
        self.pipeline = self._initialize_pipeline()

    def _initialize_pipeline(self):
        controlnet = ControlNetModel.from_pretrained(self.canny_control_model, torch_dtype=torch.float16)
        pipe = StableDiffusionControlNetPipeline.from_pretrained(
            self.model_name,
            controlnet=controlnet,
            torch_dtype=torch.float16
        ).to(self.device)
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        pipe.enable_model_cpu_offload()
        return pipe

    def transform_image(self, image, prompt, low_threshold=100, high_threshold=200):
        edge_image = cv2.Canny(image, low_threshold, high_threshold)
        edge_image = np.stack((edge_image, edge_image, edge_image), axis=-1)  # Convert to 3-channel image
        transformed_images = self.pipeline(
            prompt=[prompt],
            images=[Image.fromarray(edge_image)],
            num_inference_steps=20
        ).images
        return transformed_images[0]

# %% ../nbs/01_diffuse.ipynb 6
class PoseImageTransformer(BaseTransformer):
    def __init__(
            self,
            *args, 
            pose_control_model=Config.CONTROL_NET_CANNY_MODEL,
            pose_det_model=Config.POSE_DET_MODEL,
            **kwargs,
        ):
        super().__init__(*args, **kwargs)
        self.pose_control_model = pose_control_model
        self.pose_det_model = pose_det_model
        self.pipeline = self._initialize_pipeline()
        self.pose_model = OpenposeDetector.from_pretrained(self.pose_det_model)

    def _initialize_pipeline(self):
        controlnet = ControlNetModel.from_pretrained(
            self.pose_control_model, torch_dtype=torch.float16
        )
        pipe = StableDiffusionControlNetPipeline.from_pretrained(
            self.model_name, controlnet=controlnet, torch_dtype=torch.float16
        ).to(self.device)
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        pipe.enable_model_cpu_offload()
        return pipe

    def transform_image(self, image, prompt):
        pose_image = self.pose_model(image)
        transformed_images = self.pipeline(
            prompt=[prompt],
            images=[pose_image],
            num_inference_steps=20
        ).images
        return transformed_images[0]

# %% ../nbs/01_diffuse.ipynb 7
class CombinedImageTransformer(BaseTransformer):
    def __init__(
            self,
            *args, 
            canny_control_model=Config.CONTROL_NET_CANNY_MODEL,
            pose_control_model=Config.CONTROL_NET_CANNY_MODEL,
            pose_det_model=Config.POSE_DET_MODEL,
            **kwargs,
        ):
        super().__init__(*args, **kwargs)
        self.canny_control_model = canny_control_model
        self.pose_control_model = pose_control_model
        self.pose_det_model = pose_det_model
        self.pipeline = self._initialize_pipeline()
        self.pose_model = OpenposeDetector.from_pretrained(self.pose_det_model)

    def _initialize_pipeline(self):
        controlnet = [
            ControlNetModel.from_pretrained(self.pose_control_model, torch_dtype=torch.float16),
            ControlNetModel.from_pretrained(self.canny_control_model, torch_dtype=torch.float16),
        ]
        pipe = StableDiffusionControlNetPipeline.from_pretrained(
            self.model_name,
            controlnet=controlnet,
            torch_dtype=torch.float16
        ).to(self.device)
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        pipe.enable_model_cpu_offload()
        return pipe

    def transform_image(self, image, prompt):
        """
        Transforms an image based on a given prompt using combined control nets for pose and edges.

        Args:
            image: A numpy array of the image to transform.
            prompt (str): The creative prompt to guide the image transformation.

        Returns:
            PIL.Image: The transformed image.
        """
        prepared_pose_image = self.prepare_pose_image(image)
        prepared_canny_image = self.prepare_canny_image(image)
        images = [prepared_pose_image, prepared_canny_image]
        negative_prompt = "monochrome, lowres, bad anatomy, worst quality, low quality"
        controlnet_conditioning_scale = [1.0, 0.8]
        num_inference_steps = 20

        transformed_images = self.pipeline(
            prompt=prompt,
            images=images,
            num_inference_steps=num_inference_steps,
            generator=torch.Generator(device="cpu").manual_seed(1),
            negative_prompt=[negative_prompt],
            controlnet_conditioning_scale=controlnet_conditioning_scale
        ).images

        return transformed_images[0]

    def prepare_canny_image(self, image, low_threshold=100, high_threshold=200):
        canny_image = cv2.Canny(image, low_threshold, high_threshold)
        zero_start = canny_image.shape[1] // 4
        zero_end = zero_start + canny_image.shape[1] // 2
        canny_image[:, zero_start:zero_end] = 0
        canny_image = np.stack((canny_image, canny_image, canny_image), axis=-1)
        return Image.fromarray(canny_image)

    def prepare_pose_image(self, image):
        return self.pose_model(image)

# %% ../nbs/01_diffuse.ipynb 8
def get_transformer(transformer_type):
    if transformer_type == "regular":
        return ImageTransformer()
    elif transformer_type == "canny":
        return EdgeImageTransformer()
    elif transformer_type == "pose":
        return PoseImageTransformer()
    elif transformer_type == "combined":
        return CombinedImageTransformer()
    else:
        raise ValueError("Unknown transformer type provided")


# %% ../nbs/01_diffuse.ipynb 10
if __name__ == "__main__":
    app.run(debug=True)

